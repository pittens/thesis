{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"1_preprocessing.ipynb","provenance":[],"collapsed_sections":["gfJERrLf16a9","D5dTLLav16bG","Nj0ds80016bO","UEYaCFKT16bl","_tYKDAkS16bz","mc9fT-j-16b3","Wc447X8D16b_","7xTv1oZV16cQ","8dEzc4za16cU","zOVomjXQ16ca","wBggiOgJ16cg","I288WLkA16cp","J52fdTs8MYh6","dfGm7noe16dK","nAUpm05ANOxt"],"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"310xav8Y16at","colab_type":"text"},"source":["# 1. Data preprocessing\n","This script includes the steps of preprocessing.\n","*N.B. Approximately 25 minutes of execution time.*"]},{"cell_type":"markdown","metadata":{"id":"lNFKlpjCMqnI","colab_type":"text"},"source":["## 1.1. Preliminary"]},{"cell_type":"markdown","metadata":{"id":"XmOSvzSbNG4F","colab_type":"text"},"source":["Import modules."]},{"cell_type":"code","metadata":{"id":"u02qj-Yv16a2","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","import os\n","import itertools as it\n","from pandas import Series\n","import warnings\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import normalize\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.utils import to_categorical"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Br2pR5pp5eNV","colab_type":"text"},"source":["Mount drive and change current working directory."]},{"cell_type":"code","metadata":{"id":"Bt3RnzZW5c-A","colab_type":"code","colab":{}},"source":["drive.mount('/content/drive', force_remount = True)\n","os.chdir(\"/content/drive/My Drive/thesis/\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfJERrLf16a9","colab_type":"text"},"source":["## 1.2. Human-Animal Affective Robot Touch (HAART)"]},{"cell_type":"markdown","metadata":{"id":"5CUkcPtC16a_","colab_type":"text"},"source":["The HAART dataset is available in a form where it has already been split into a training and test set. Import the CSV data."]},{"cell_type":"code","metadata":{"id":"N7ob4qFo16bB","colab_type":"code","colab":{}},"source":["HAART_import_train = pd.read_csv(\"data/HAART DataSet/training.csv\")\n","HAART_import_test = pd.read_csv(\"data/HAART DataSet/testWITHLABELS.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D5dTLLav16bG","colab_type":"text"},"source":["#### 1.2.1. Missing 'Sequence' column in training set"]},{"cell_type":"markdown","metadata":{"id":"cbePIT7v16bI","colab_type":"text"},"source":["However, the 'Sequence' column is missing in the training set. Each individual gesture capture uses 432 rows (54Hz x 8 seconds), so these must be added."]},{"cell_type":"code","metadata":{"id":"mZvYc-Fx16bK","colab_type":"code","colab":{}},"source":["seq = it.cycle(range(1,433)) #Create an infinite iterator with ascending values from 1 to 432.\n","HAART_import_train[\"Sequence\"] = [next(seq) for count in range(HAART_import_train.shape[0])] #Fill the column with these values."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nj0ds80016bO","colab_type":"text"},"source":["#### 1.2.2. Consistent column headers"]},{"cell_type":"markdown","metadata":{"id":"zM0iKmuf16bQ","colab_type":"text"},"source":["Where the headers of the test set do not contain parentheses, this is the case for the training set. In order to get a correct reconnection, this must be adjusted."]},{"cell_type":"code","metadata":{"id":"BgGv7p2b16bS","colab_type":"code","colab":{}},"source":["HAART_import_train.columns = HAART_import_train.columns.str.replace('\"', '') #Remove parentheses in train set headers."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jAMc6LHK16bX","colab_type":"text"},"source":["The test (ParticipantID) and training (ParticipantNo) sets have a different header name for the number of the participant. This must also be adjusted.\n","    "]},{"cell_type":"code","metadata":{"id":"TPu0inLq16bY","colab_type":"code","colab":{}},"source":["HAART_import_train = HAART_import_train.rename({\"ParticipantNo\": \"ParticipantID\"}, axis = \"columns\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGdPNDpg16bd","colab_type":"text"},"source":["The column headers of the train set all contain an unnecessary space that does not occur in the test set. These will be removed to ensure that they can later be merged based on this information."]},{"cell_type":"code","metadata":{"id":"aiSqNpIf16bf","colab_type":"code","colab":{}},"source":["HAART_import_train = HAART_import_train.rename(columns = lambda x: x.strip())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEYaCFKT16bl","colab_type":"text"},"source":["#### 1.2.3. Reconnect the old train and test set"]},{"cell_type":"markdown","metadata":{"id":"Z86h0H4f16bm","colab_type":"text"},"source":["The following code gives information about both datasets. In total the reconnected set contains 358128 rows."]},{"cell_type":"code","metadata":{"id":"lw1sGkWF16bo","colab_type":"code","outputId":"54b4a6af-ebaa-4c64-e627-21377e1f41e7","executionInfo":{"status":"ok","timestamp":1574081756003,"user_tz":-60,"elapsed":5405,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["trn_rows, trn_col = HAART_import_train.shape\n","tst_rows, tst_col = HAART_import_test.shape\n","print(\"The training set has\",trn_rows,\"rows and\",trn_col,\"columns.\") #Give information about training set.\n","print(\"The test set has\",tst_rows,\"rows and\",tst_col,\"columns.\") #Give information about test set."],"execution_count":0,"outputs":[{"output_type":"stream","text":["The training set has 249696 rows and 69 columns.\n","The test set has 108432 rows and 69 columns.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XVrVdNMX16bu","colab_type":"text"},"source":["Join the train and test set based on the column headers. Use 'how = \"outer\"' to use union of keys from both frames."]},{"cell_type":"code","metadata":{"id":"Sdz1HyXD16bw","colab_type":"code","colab":{}},"source":["HAART_merge = pd.merge(HAART_import_test, HAART_import_train, how = \"outer\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tYKDAkS16bz","colab_type":"text"},"source":["#### 1.2.4. Remove irrelevant gestures / Instance selection"]},{"cell_type":"markdown","metadata":{"id":"a1uYx6XM16b0","colab_type":"text"},"source":["Only the classes that are available in both datasets will be used. This means that the 'notouch' gesture will be deleted in the HAART dataset. The remaining gestures are 'stroke', 'scratch', 'constant' (= press), 'tickle', 'rub', and 'pat'."]},{"cell_type":"code","metadata":{"id":"PIN2Od3V16b1","colab_type":"code","colab":{}},"source":["HAART_notouch = HAART_merge[~HAART_merge.Gesture.str.contains(\"notouch\")]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mc9fT-j-16b3","colab_type":"text"},"source":["#### 1.2.5. Data harmonization"]},{"cell_type":"markdown","metadata":{"id":"ri4PWPNQ16b4","colab_type":"text"},"source":["In order to create one cohesive data set, several changes has to be made so the HAART is compatible with the CoST.\n","\n","A problem we encounter is that the HAART gestures are written out in the column, while in the CoST dataset these are represented in numbers, each representing a gesture. For a good harmonization, the written gestures are converted to numbers.\n","\n","Gestures that will be used with number:\n","- 4 Pat\n","- 7 Press ('constant' in HAART)\n","- 8 Rub\n","- 9 Scratch\n","- 12 Stroke\n","- 14 Tickle"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"rlrtb7dQ16b5","colab_type":"code","colab":{}},"source":["replace_numbers = {\"Gesture\": {\"stroke\": 12, \n","                               \"scratch\": 9, \n","                               \"constant\": 7, \n","                               \"tickle\": 14, \n","                               \"rub\": 8, \n","                               \"pat\": 4}\n","                  } #Create a dictionary which contains each category with the number.\n","\n","HAART_replace = HAART_notouch.copy() #Make a copy to prevent a \"SettingWithCopyWarning\".\n","\n","HAART_replace.replace(replace_numbers, inplace = True) #Use this dictionary to replace text with numbers."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnru7Zjo16b7","colab_type":"text"},"source":["Not relevant columns may be removed and other columns may be adjusted so that the names match the CoST set."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"u505AxpW16b8","colab_type":"code","colab":{}},"source":["HAART_replace.drop([\"Substrate\", \"Cover\"], axis = 1, inplace = True) #Remove irrelevant columns.\n","\n","col_num = list(range(1,65)) #Create a list with the numbers for the headers of all 64 channels.\n","new_cols = [] #Empty list which will be filled with new header names.\n","for _ in col_num:\n","    name = \"ch\"+str(_)\n","    new_cols.append(name) #Create new header names (similar to CoST) and append to new_cols.\n","\n","HAART_replace.rename(columns = dict(zip(HAART_replace.columns[3:], new_cols)), inplace = True) #Replace names.\n","\n","HAART_complete = HAART_replace.rename(columns = {\"ParticipantID\": \"subject\", \n","                                                 \"Gesture\": \"gesture\", \n","                                                 \"Sequence\": \"frame\"}) #Harmonize other columns with CoST."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0TccJda16b-","colab_type":"text"},"source":["The \"HAART_complete\" DataFrame is structurally identical to the final CoST set. However, the content still needs to be normalized."]},{"cell_type":"markdown","metadata":{"id":"Wc447X8D16b_","colab_type":"text"},"source":["#### 1.2.6. Normalization"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"8V8W7vQq16b_","colab_type":"code","outputId":"014cd963-f7bb-4a9b-e49e-22e41a23a05f","executionInfo":{"status":"ok","timestamp":1574081760660,"user_tz":-60,"elapsed":9516,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["HAART = HAART_complete.drop([\"subject\", \"gesture\", \"frame\"], axis = 1) #Continue working with the data that will be normalized.\n","HAART.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ch1</th>\n","      <th>ch2</th>\n","      <th>ch3</th>\n","      <th>ch4</th>\n","      <th>ch5</th>\n","      <th>ch6</th>\n","      <th>ch7</th>\n","      <th>ch8</th>\n","      <th>ch9</th>\n","      <th>ch10</th>\n","      <th>ch11</th>\n","      <th>ch12</th>\n","      <th>ch13</th>\n","      <th>ch14</th>\n","      <th>ch15</th>\n","      <th>ch16</th>\n","      <th>ch17</th>\n","      <th>ch18</th>\n","      <th>ch19</th>\n","      <th>ch20</th>\n","      <th>ch21</th>\n","      <th>ch22</th>\n","      <th>ch23</th>\n","      <th>ch24</th>\n","      <th>ch25</th>\n","      <th>ch26</th>\n","      <th>ch27</th>\n","      <th>ch28</th>\n","      <th>ch29</th>\n","      <th>ch30</th>\n","      <th>ch31</th>\n","      <th>ch32</th>\n","      <th>ch33</th>\n","      <th>ch34</th>\n","      <th>ch35</th>\n","      <th>ch36</th>\n","      <th>ch37</th>\n","      <th>ch38</th>\n","      <th>ch39</th>\n","      <th>ch40</th>\n","      <th>ch41</th>\n","      <th>ch42</th>\n","      <th>ch43</th>\n","      <th>ch44</th>\n","      <th>ch45</th>\n","      <th>ch46</th>\n","      <th>ch47</th>\n","      <th>ch48</th>\n","      <th>ch49</th>\n","      <th>ch50</th>\n","      <th>ch51</th>\n","      <th>ch52</th>\n","      <th>ch53</th>\n","      <th>ch54</th>\n","      <th>ch55</th>\n","      <th>ch56</th>\n","      <th>ch57</th>\n","      <th>ch58</th>\n","      <th>ch59</th>\n","      <th>ch60</th>\n","      <th>ch61</th>\n","      <th>ch62</th>\n","      <th>ch63</th>\n","      <th>ch64</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>12</td>\n","      <td>14</td>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>37</td>\n","      <td>17</td>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13</td>\n","      <td>17</td>\n","      <td>15</td>\n","      <td>19</td>\n","      <td>31</td>\n","      <td>16</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>14</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>63</td>\n","      <td>26</td>\n","      <td>22</td>\n","      <td>19</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>22</td>\n","      <td>30</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23</td>\n","      <td>22</td>\n","      <td>20</td>\n","      <td>22</td>\n","      <td>38</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>55</td>\n","      <td>71</td>\n","      <td>27</td>\n","      <td>23</td>\n","      <td>18</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>34</td>\n","      <td>41</td>\n","      <td>29</td>\n","      <td>31</td>\n","      <td>20</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ch1  ch2  ch3  ch4  ch5  ch6  ch7  ...  ch58  ch59  ch60  ch61  ch62  ch63  ch64\n","0    5    1    1    2    9   15    9  ...     2     0     3     3     3     1     0\n","1    4    9    4    6   10   12    6  ...    19    19    37    17    13     5     4\n","2   13   17   15   19   31   16    7  ...    18    22    30    15     9     7     6\n","3   23   22   20   22   38   11    7  ...     8     8    11     6     2     2     2\n","4   21   21   19   20   30    6    4  ...     7     8     6     7     4     2     2\n","\n","[5 rows x 64 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"nr8gMx9U16cC","colab_type":"code","colab":{}},"source":["HAART_np = HAART.values #Transform HAART DataFrame to a 2-dimensional array.\n","HAART_norm = [] #Create empty list in which normalized arrays will be added.\n","\n","#This rule has only been added to remove a warning that indicates that the input of the MinMaxScaler has been changed.\n","warnings.filterwarnings(action = 'ignore') \n","\n","for row in HAART_np:\n","    series = Series(np.ndarray.tolist(row)) #Define series.\n","    #Prepare data for normalization.\n","    values = series.values \n","    values = values.reshape((len(values), 1))\n","    #Train the normalization. Values can be between 0 and 1.\n","    scaler = MinMaxScaler(feature_range=(0, 1)) \n","    scaler = scaler.fit(values)\n","    #Append transformed data to list.\n","    HAART_norm.append(np.asarray(scaler.transform(values)))\n","    \n","HAART_norm = np.array(HAART_norm) #Transform list into a 2-dimensional array."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qgYLGcRp16cF","colab_type":"text"},"source":["The two-dimensional array must be reshaped to a three-dimensional array so that it meets the expected LSTM imput. Besides the 3D requirement, the input must be comprised of samples, time steps, and features in that order."]},{"cell_type":"code","metadata":{"id":"mkewtifV16cF","colab_type":"code","outputId":"192ca034-3884-4847-fc4b-5bd3b4d47ccb","executionInfo":{"status":"ok","timestamp":1574081886424,"user_tz":-60,"elapsed":135140,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_HAART = np.reshape(HAART_norm, (710,432,64)) #Reshape to a 3D-array which is the intended input is for the LSTM model.\n","\n","print(\"The old shape was\", HAART_norm.shape, \", the new shape is\", x_HAART.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The old shape was (306720, 64, 1) , the new shape is (710, 432, 64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wvJxbqqB16cI","colab_type":"text"},"source":["The target variable (y) must also be stored in the correct array shape (710,)."]},{"cell_type":"code","metadata":{"id":"i8tXKOY_16cI","colab_type":"code","colab":{}},"source":["y = np.asarray(HAART_complete[\"gesture\"]) #Get information out of dataset and transform to array.\n","y = np.reshape(y, (710,432)) #Transform to 2D array. "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZUEC0P5616cM","colab_type":"text"},"source":["The target of each frame is now stored in a 2D array. The target value now occurs 432 times in every gesture capture. With a loop this will be solved. The target will be saved in a new array named \"y_HAART\". "]},{"cell_type":"code","metadata":{"id":"Uu5vGOhb16cN","colab_type":"code","colab":{}},"source":["y_HAART = []\n","for target in y:\n","    y_HAART.append(int(np.mean(target)))\n","\n","y_HAART = np.array(y_HAART) #Transform list to array."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"axzSCFY_XIMY","colab_type":"text"},"source":["In order to use the categorical crossentropy loss function, the y_HAART has to be in categorical format and must be ranged from 0 to 5."]},{"cell_type":"code","metadata":{"id":"siC6tKHDXCN9","colab_type":"code","colab":{}},"source":["old_label = [4, 7, 8, 9, 12, 14]\n","new_label = [0, 1, 2, 3, 4, 5]\n","\n","for N, O in zip(new_label, old_label):\n","    y_HAART[y_HAART == O] = N\n","\n","y_HAART = to_categorical(y_HAART)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKgxG-sI16cP","colab_type":"text"},"source":["From this point the HAART set is sufficiently prepared for an aggregation with the CoST set and in the right format for the LSTM."]},{"cell_type":"markdown","metadata":{"id":"7xTv1oZV16cQ","colab_type":"text"},"source":["## 1.3. Corpus of Social Touch (CoST)"]},{"cell_type":"markdown","metadata":{"id":"zExPa61816cR","colab_type":"text"},"source":["The CoST dataset is made available by 4TU.Centre for Research Data. Import the CSV data via URL."]},{"cell_type":"code","metadata":{"id":"UfuS3sY816cR","colab_type":"code","colab":{}},"source":["url = \"https://data.4tu.nl/repository/uuid:5ef62345-3b3e-479c-8e1d-c922748c9b29/DATA\"\n","CoST_import = pd.read_csv(url)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8dEzc4za16cU","colab_type":"text"},"source":["#### 1.3.1. Consistent column headers"]},{"cell_type":"markdown","metadata":{"id":"3UTVV0mC16cX","colab_type":"text"},"source":["The most of the column headers contain an unnecessary space. These will be removed to ensure that they can later be merged."]},{"cell_type":"code","metadata":{"id":"rsB3qlG_16cY","colab_type":"code","colab":{}},"source":["CoST_import = CoST_import.rename(columns = lambda x: x.strip())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOVomjXQ16ca","colab_type":"text"},"source":["#### 1.3.2. Remove irrelevant gestures / Instance selection"]},{"cell_type":"markdown","metadata":{"id":"ofEKyc3c16ca","colab_type":"text"},"source":["First, the gestures that will not be used can be removed."]},{"cell_type":"code","metadata":{"id":"ZWbTU_fK16cb","colab_type":"code","colab":{}},"source":["irr_col = [1,2,3,5,6,10,11,13] #Irrelevant gestures.\n","for number in irr_col: #Loop over gestures.\n","    CoST_import = CoST_import[CoST_import.gesture != number] #Remove gesture from dataset."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-RAMTUU16cd","colab_type":"text"},"source":["The numbers of gestures that occur in both sets are: 4, 7, 8, 9, 12, 14."]},{"cell_type":"code","metadata":{"id":"B9DCFNYU16ce","colab_type":"code","outputId":"7656d347-19fe-404a-e016-2a90d0e817cd","executionInfo":{"status":"ok","timestamp":1574081915067,"user_tz":-60,"elapsed":162503,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"The following gestures are left:\", CoST_import.gesture.unique())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The following gestures are left: [ 4  7  8  9 12 14]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wBggiOgJ16cg","colab_type":"text"},"source":["#### 1.3.3. Data harmonization"]},{"cell_type":"markdown","metadata":{"id":"6ifVyMds16cg","colab_type":"text"},"source":["Not relevant column can be removed."]},{"cell_type":"code","metadata":{"id":"XiYDwNBq16ch","colab_type":"code","colab":{}},"source":["CoST_import.drop([\"variant\"], axis = 1, inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBuMg_Se16cl","colab_type":"text"},"source":["Within the HAART set, subjects are indicated by means of a letter-number combination. This has saved the column as an 'object' data type. Only a number is used for the CoST dataset, so the column is saved as data type 'int64'. To ensure that the aggregation runs smoothly, the 'subject' column of the CoST set will (temporarily) be converted. The other way around is not possible. In addition, the index must be reset for at a later stage."]},{"cell_type":"code","metadata":{"id":"Qzfo3S1i16cm","colab_type":"code","colab":{}},"source":["CoST_import[\"subject\"] = CoST_import[\"subject\"].apply(str)\n","CoST_complete = CoST_import\n","CoST_complete = CoST_complete.reset_index(drop = True) #Reset index."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3h24YhlF16co","colab_type":"text"},"source":["The \"CoST_complete\" DataFrame is structurally identical to the final HAART DataFrame. However, the content still needs to be normalized."]},{"cell_type":"markdown","metadata":{"id":"I288WLkA16cp","colab_type":"text"},"source":["#### 1.3.4. Normalization"]},{"cell_type":"code","metadata":{"id":"Tzq9CSKh16cp","colab_type":"code","outputId":"c309468f-61da-40b1-d60e-1600786bafca","executionInfo":{"status":"ok","timestamp":1574081915826,"user_tz":-60,"elapsed":162916,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["CoST = CoST_complete.drop([\"subject\", \"gesture\", \"frame\"], axis = 1) #Continue working with the data that will be normalized.\n","CoST.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ch1</th>\n","      <th>ch2</th>\n","      <th>ch3</th>\n","      <th>ch4</th>\n","      <th>ch5</th>\n","      <th>ch6</th>\n","      <th>ch7</th>\n","      <th>ch8</th>\n","      <th>ch9</th>\n","      <th>ch10</th>\n","      <th>ch11</th>\n","      <th>ch12</th>\n","      <th>ch13</th>\n","      <th>ch14</th>\n","      <th>ch15</th>\n","      <th>ch16</th>\n","      <th>ch17</th>\n","      <th>ch18</th>\n","      <th>ch19</th>\n","      <th>ch20</th>\n","      <th>ch21</th>\n","      <th>ch22</th>\n","      <th>ch23</th>\n","      <th>ch24</th>\n","      <th>ch25</th>\n","      <th>ch26</th>\n","      <th>ch27</th>\n","      <th>ch28</th>\n","      <th>ch29</th>\n","      <th>ch30</th>\n","      <th>ch31</th>\n","      <th>ch32</th>\n","      <th>ch33</th>\n","      <th>ch34</th>\n","      <th>ch35</th>\n","      <th>ch36</th>\n","      <th>ch37</th>\n","      <th>ch38</th>\n","      <th>ch39</th>\n","      <th>ch40</th>\n","      <th>ch41</th>\n","      <th>ch42</th>\n","      <th>ch43</th>\n","      <th>ch44</th>\n","      <th>ch45</th>\n","      <th>ch46</th>\n","      <th>ch47</th>\n","      <th>ch48</th>\n","      <th>ch49</th>\n","      <th>ch50</th>\n","      <th>ch51</th>\n","      <th>ch52</th>\n","      <th>ch53</th>\n","      <th>ch54</th>\n","      <th>ch55</th>\n","      <th>ch56</th>\n","      <th>ch57</th>\n","      <th>ch58</th>\n","      <th>ch59</th>\n","      <th>ch60</th>\n","      <th>ch61</th>\n","      <th>ch62</th>\n","      <th>ch63</th>\n","      <th>ch64</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>33</td>\n","      <td>67</td>\n","      <td>70</td>\n","      <td>58</td>\n","      <td>61</td>\n","      <td>47</td>\n","      <td>39</td>\n","      <td>25</td>\n","      <td>30</td>\n","      <td>70</td>\n","      <td>71</td>\n","      <td>67</td>\n","      <td>65</td>\n","      <td>49</td>\n","      <td>42</td>\n","      <td>25</td>\n","      <td>35</td>\n","      <td>95</td>\n","      <td>93</td>\n","      <td>84</td>\n","      <td>85</td>\n","      <td>57</td>\n","      <td>53</td>\n","      <td>27</td>\n","      <td>38</td>\n","      <td>131</td>\n","      <td>124</td>\n","      <td>102</td>\n","      <td>101</td>\n","      <td>67</td>\n","      <td>55</td>\n","      <td>28</td>\n","      <td>37</td>\n","      <td>109</td>\n","      <td>102</td>\n","      <td>94</td>\n","      <td>91</td>\n","      <td>65</td>\n","      <td>57</td>\n","      <td>28</td>\n","      <td>29</td>\n","      <td>61</td>\n","      <td>56</td>\n","      <td>58</td>\n","      <td>55</td>\n","      <td>42</td>\n","      <td>38</td>\n","      <td>22</td>\n","      <td>27</td>\n","      <td>43</td>\n","      <td>44</td>\n","      <td>42</td>\n","      <td>41</td>\n","      <td>34</td>\n","      <td>30</td>\n","      <td>21</td>\n","      <td>29</td>\n","      <td>51</td>\n","      <td>54</td>\n","      <td>52</td>\n","      <td>47</td>\n","      <td>32</td>\n","      <td>33</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33</td>\n","      <td>70</td>\n","      <td>72</td>\n","      <td>64</td>\n","      <td>61</td>\n","      <td>46</td>\n","      <td>41</td>\n","      <td>24</td>\n","      <td>32</td>\n","      <td>71</td>\n","      <td>70</td>\n","      <td>67</td>\n","      <td>67</td>\n","      <td>47</td>\n","      <td>40</td>\n","      <td>25</td>\n","      <td>35</td>\n","      <td>94</td>\n","      <td>95</td>\n","      <td>86</td>\n","      <td>84</td>\n","      <td>60</td>\n","      <td>52</td>\n","      <td>25</td>\n","      <td>35</td>\n","      <td>129</td>\n","      <td>122</td>\n","      <td>103</td>\n","      <td>103</td>\n","      <td>68</td>\n","      <td>61</td>\n","      <td>28</td>\n","      <td>40</td>\n","      <td>101</td>\n","      <td>104</td>\n","      <td>92</td>\n","      <td>92</td>\n","      <td>62</td>\n","      <td>56</td>\n","      <td>27</td>\n","      <td>31</td>\n","      <td>59</td>\n","      <td>62</td>\n","      <td>60</td>\n","      <td>55</td>\n","      <td>42</td>\n","      <td>38</td>\n","      <td>23</td>\n","      <td>28</td>\n","      <td>46</td>\n","      <td>42</td>\n","      <td>44</td>\n","      <td>42</td>\n","      <td>34</td>\n","      <td>31</td>\n","      <td>20</td>\n","      <td>29</td>\n","      <td>50</td>\n","      <td>53</td>\n","      <td>51</td>\n","      <td>50</td>\n","      <td>39</td>\n","      <td>34</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>32</td>\n","      <td>70</td>\n","      <td>69</td>\n","      <td>63</td>\n","      <td>62</td>\n","      <td>47</td>\n","      <td>38</td>\n","      <td>25</td>\n","      <td>33</td>\n","      <td>72</td>\n","      <td>73</td>\n","      <td>66</td>\n","      <td>69</td>\n","      <td>49</td>\n","      <td>43</td>\n","      <td>24</td>\n","      <td>34</td>\n","      <td>95</td>\n","      <td>94</td>\n","      <td>86</td>\n","      <td>86</td>\n","      <td>58</td>\n","      <td>52</td>\n","      <td>28</td>\n","      <td>37</td>\n","      <td>129</td>\n","      <td>124</td>\n","      <td>102</td>\n","      <td>102</td>\n","      <td>69</td>\n","      <td>61</td>\n","      <td>27</td>\n","      <td>37</td>\n","      <td>109</td>\n","      <td>102</td>\n","      <td>93</td>\n","      <td>92</td>\n","      <td>64</td>\n","      <td>56</td>\n","      <td>28</td>\n","      <td>30</td>\n","      <td>59</td>\n","      <td>58</td>\n","      <td>59</td>\n","      <td>58</td>\n","      <td>42</td>\n","      <td>41</td>\n","      <td>22</td>\n","      <td>25</td>\n","      <td>43</td>\n","      <td>46</td>\n","      <td>45</td>\n","      <td>43</td>\n","      <td>34</td>\n","      <td>32</td>\n","      <td>21</td>\n","      <td>26</td>\n","      <td>52</td>\n","      <td>54</td>\n","      <td>53</td>\n","      <td>47</td>\n","      <td>42</td>\n","      <td>37</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>31</td>\n","      <td>70</td>\n","      <td>70</td>\n","      <td>66</td>\n","      <td>63</td>\n","      <td>49</td>\n","      <td>40</td>\n","      <td>22</td>\n","      <td>32</td>\n","      <td>71</td>\n","      <td>71</td>\n","      <td>67</td>\n","      <td>67</td>\n","      <td>49</td>\n","      <td>43</td>\n","      <td>24</td>\n","      <td>38</td>\n","      <td>96</td>\n","      <td>93</td>\n","      <td>85</td>\n","      <td>84</td>\n","      <td>60</td>\n","      <td>52</td>\n","      <td>25</td>\n","      <td>39</td>\n","      <td>127</td>\n","      <td>123</td>\n","      <td>102</td>\n","      <td>103</td>\n","      <td>68</td>\n","      <td>60</td>\n","      <td>27</td>\n","      <td>38</td>\n","      <td>108</td>\n","      <td>102</td>\n","      <td>92</td>\n","      <td>93</td>\n","      <td>63</td>\n","      <td>58</td>\n","      <td>26</td>\n","      <td>29</td>\n","      <td>59</td>\n","      <td>59</td>\n","      <td>57</td>\n","      <td>56</td>\n","      <td>41</td>\n","      <td>37</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>46</td>\n","      <td>45</td>\n","      <td>42</td>\n","      <td>42</td>\n","      <td>36</td>\n","      <td>31</td>\n","      <td>19</td>\n","      <td>31</td>\n","      <td>52</td>\n","      <td>53</td>\n","      <td>51</td>\n","      <td>50</td>\n","      <td>35</td>\n","      <td>39</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>34</td>\n","      <td>70</td>\n","      <td>69</td>\n","      <td>62</td>\n","      <td>63</td>\n","      <td>49</td>\n","      <td>41</td>\n","      <td>26</td>\n","      <td>31</td>\n","      <td>72</td>\n","      <td>71</td>\n","      <td>68</td>\n","      <td>63</td>\n","      <td>49</td>\n","      <td>42</td>\n","      <td>26</td>\n","      <td>34</td>\n","      <td>96</td>\n","      <td>93</td>\n","      <td>82</td>\n","      <td>85</td>\n","      <td>59</td>\n","      <td>53</td>\n","      <td>26</td>\n","      <td>38</td>\n","      <td>126</td>\n","      <td>123</td>\n","      <td>102</td>\n","      <td>102</td>\n","      <td>67</td>\n","      <td>59</td>\n","      <td>27</td>\n","      <td>37</td>\n","      <td>107</td>\n","      <td>103</td>\n","      <td>93</td>\n","      <td>92</td>\n","      <td>65</td>\n","      <td>57</td>\n","      <td>28</td>\n","      <td>30</td>\n","      <td>61</td>\n","      <td>60</td>\n","      <td>57</td>\n","      <td>56</td>\n","      <td>43</td>\n","      <td>35</td>\n","      <td>23</td>\n","      <td>26</td>\n","      <td>43</td>\n","      <td>47</td>\n","      <td>44</td>\n","      <td>44</td>\n","      <td>34</td>\n","      <td>28</td>\n","      <td>20</td>\n","      <td>28</td>\n","      <td>51</td>\n","      <td>51</td>\n","      <td>51</td>\n","      <td>48</td>\n","      <td>37</td>\n","      <td>36</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ch1  ch2  ch3  ch4  ch5  ch6  ch7  ...  ch58  ch59  ch60  ch61  ch62  ch63  ch64\n","0   33   67   70   58   61   47   39  ...    51    54    52    47    32    33    22\n","1   33   70   72   64   61   46   41  ...    50    53    51    50    39    34    23\n","2   32   70   69   63   62   47   38  ...    52    54    53    47    42    37    24\n","3   31   70   70   66   63   49   40  ...    52    53    51    50    35    39    22\n","4   34   70   69   62   63   49   41  ...    51    51    51    48    37    36    21\n","\n","[5 rows x 64 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"setV7BCJ16cs","colab_type":"code","colab":{}},"source":["CoST_np = CoST.values #Transform CoST DataFrame to a 2-dimensional array.\n","CoST_norm = [] #Create empty list in which normalized arrays will be added.\n","\n","#This rule has only been added to remove a warning that indicates that the input of the MinMaxScaler has been changed.\n","warnings.filterwarnings(action = 'ignore') \n","\n","for row in CoST_np:\n","    series = Series(np.ndarray.tolist(row)) #Define series.\n","    #Prepare data for normalization.\n","    values = series.values \n","    values = values.reshape((len(values), 1))\n","    #Train the normalization. Values can be between 0 and 1.\n","    scaler = MinMaxScaler(feature_range = (0, 1)) \n","    scaler = scaler.fit(values)\n","    #Append transformed data to list.\n","    CoST_norm.append(np.asarray(scaler.transform(values)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l_PpFpLgTzzx","colab_type":"text"},"source":["First, the normalized data needs to be reshaped to a 2 dimensional array. After that, it can be transformed to DataFrame. The CoST_norm sensor data will replace the CoST_complete sensor data via a for-loop."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XM9r3660QIwm","colab":{}},"source":["CoST_norm = np.array(CoST_norm)\n","CoST_norm = np.reshape(CoST_norm, (788224, 64))\n","CoST_norm = pd.DataFrame(CoST_norm)\n","\n","count = 0 #Variable that goes up to 64 so the columns can be replaced by the normalized ones.\n","\n","for column in CoST_complete.iloc[:,3:]:\n","  CoST_complete[column] = CoST_norm[count]\n","  count += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeYGOprEMQAv","colab_type":"code","outputId":"b9693038-f4eb-4db1-b1b9-7eb457f2e72d","executionInfo":{"status":"ok","timestamp":1574082249866,"user_tz":-60,"elapsed":496762,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"The longest gestures contains\",max(CoST_complete[\"frame\"]), \"frames.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The longest gestures contains 1489 frames.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J3-ZKnoX2IQ6","colab_type":"text"},"source":["Because the data is too sparse when using 1489 frames in the second dimension and because the HAART set has 432 frames, the COST will also contain this number of frames. The desired 'x_COST' 3D-array output shape is therefore (*number of gestures:* 3342, *frames:* 432, *sensor grid:* 64). First all sensors of all frames that belong together are merged. We get a list containing 3342 new lists with arrays of 64 values. "]},{"cell_type":"code","metadata":{"id":"eeIZBGrrfELM","colab_type":"code","colab":{}},"source":["frame = 1 #Counter variable used to count the number of frames.\n","gestures  = [] #Values of the gesture_values will be stored together here.\n","gesture_values = [] #Values of one gesture from multiple frames will be stored here.\n","for index, columns in CoST_complete.iterrows(): #Loop over dataframe.\n","  if CoST_complete.iloc[index][\"frame\"] < frame: #If new frame begins, then...\n","    gestures.append(gesture_values)\n","    gesture_values = []\n","    gesture_values.append(CoST_complete.iloc[index,3:].values)\n","    frame = 1\n","  else: #If row still belongs to same frame, then...\n","    gesture_values.append(CoST_complete.iloc[index,3:].values)\n","    frame += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J52fdTs8MYh6","colab_type":"text"},"source":["####1.3.5. Reshaping and frames removing"]},{"cell_type":"markdown","metadata":{"id":"kIWg9JbWBG32","colab_type":"text"},"source":["Every gesture now has multiple sets of 64 values seperate from each other in the list. With a for loop, all the values are combined to one array."]},{"cell_type":"code","metadata":{"id":"tx_NG4JjuBzZ","colab_type":"code","colab":{}},"source":["gestures_2D = [] #New list with gestures where all sensor values are combined in one array.\n","\n","for gesture in gestures:\n","  gesture_2D = np.concatenate(gesture, axis = 0) #Connect values in rows.\n","  gestures_2D.append(gesture_2D) #Append to new list."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6TEHgdQvM7J","colab_type":"code","colab":{}},"source":["gestures_2D = np.array(gestures_2D) #Transform list to two-dimensional array."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srRg71WbFerP","colab_type":"text"},"source":["Create function to fill empty positions with zeros."]},{"cell_type":"code","metadata":{"id":"Oh9WJetqyJAS","colab_type":"code","colab":{}},"source":["def zeros_np(dataset):\n","    \"Append zeros until max length of arrays last dimension is reached.\"\n","    lenght = np.array([len(i) for i in dataset]) #Get lengths of each row of data.\n","    mask = np.arange(lenght.max()) < lenght[:,None] #Mask of valid places in each row.\n","    output = np.zeros(mask.shape, dtype = dataset.dtype) #Put elements from data into masked positions in array.\n","    output[mask] = np.concatenate(dataset)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZDDGFZ91GKR","colab_type":"code","outputId":"aba332c7-5436-4ae4-b916-4c1b5dbf8108","executionInfo":{"status":"ok","timestamp":1574082926239,"user_tz":-60,"elapsed":1172715,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["gestures_2D = zeros_np(gestures_2D) #Apply function.\n","gestures_2D.shape #Check dimensions of array."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3342, 95296)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"O0GekafZNm0B","colab_type":"text"},"source":["The gestures_2D array is now in a 2D shape with 1489*64 = 95.296 sensor values per gestures. Most of these value are 0 because only a few gestures have 1000+ frames. Because the LSTM model cannot learn optimal on sparse data, the array will be shortened to 432 frames. By doing this, we also create consitency between the CoST and HAART dataset which already has 432 frames per gesture."]},{"cell_type":"code","metadata":{"id":"6MMfDq7wMVCL","colab_type":"code","colab":{}},"source":["gestures_2D = np.delete(gestures_2D, np.s_[27648:], 1) #Shorten the frame length of the gestures to 432 (equal to HAART)(432*64 = 27648)."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYQViu_21Tz2","colab_type":"code","colab":{}},"source":["x_COST = np.reshape(gestures_2D, (3342, 432, 64)) #Reshape to a 3D-array which is the intended input is for the LSTM model."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fnmm8HUdQU5I","colab_type":"text"},"source":["Too illustrate the minimum effect the deletion of these frames, the following code is added."]},{"cell_type":"code","metadata":{"id":"Spf0bfYLQVNZ","colab_type":"code","outputId":"170ab208-0493-4304-f788-179b439710f6","executionInfo":{"status":"ok","timestamp":1574082928265,"user_tz":-60,"elapsed":1174410,"user":{"displayName":"Tomas Pittens","photoUrl":"","userId":"13409837359802100699"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(CoST_complete.groupby('frame').count()[432:][\"ch1\"].values[0], \"gestures are affected by this decision.\")\n","print(round((3342-346)/3342, 3), \"% of the data is not affected by this decision.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["346 gestures are affected by this decision.\n","0.896 % of the data is not affected by this decision.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5FitmAmVGYOm","colab_type":"text"},"source":["The target variable (y) must also be stored in the correct array shape (3342,)."]},{"cell_type":"code","metadata":{"id":"tLoUGTsp8miv","colab_type":"code","colab":{}},"source":["frame = 1 #Frame counter.\n","y_COST = [] #New list with 3342 targets.\n","for index, columns in CoST_complete.iterrows(): #Loop over complete dataset.\n","  if CoST_complete.iloc[index][\"frame\"] < frame: #If new gesture starts...\n","    y_COST.append(CoST_complete.iloc[index][\"gesture\"]) #...Then append target to list.\n","    frame = 1\n","  else: #Else add 1 to counter.\n","    frame += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYjZ-F-kMIXH","colab_type":"code","colab":{}},"source":["y_COST = np.array(y_COST) #Transfrom to NumPy array."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bgn86sVtQv6q","colab_type":"text"},"source":["The LSTM algorithm cannot work with the categorical data directly. First the data must be transformed to numbers ranging from 0 to 5. After that, for use of categorical_crosentropy loss, the to_categorical() function is used to convert the vector of integers to a binary class matrix."]},{"cell_type":"code","metadata":{"id":"gKKTpbDCzBWc","colab_type":"code","colab":{}},"source":["old_label = [4, 7, 8, 9, 12, 14]\n","new_label = [0, 1, 2, 3, 4, 5]\n","\n","for N, O in zip(new_label, old_label): #Replace old labels by new ones.\n","    y_COST[y_COST == O] = N\n","\n","y_COST = to_categorical(y_COST) #Converts a class vector (integers) to binary class matrix."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dfGm7noe16dK","colab_type":"text"},"source":["## 1.4. CoST-HAART aggregation"]},{"cell_type":"markdown","metadata":{"id":"BXH307VlTrlx","colab_type":"text"},"source":["Aggregate/join both the input and target variables of the CoST and HAART set."]},{"cell_type":"code","metadata":{"id":"K8emteXGUnV0","colab_type":"code","colab":{}},"source":["x_COSTHAART = np.concatenate((x_COST, x_HAART))\n","y_COSTHAART = np.concatenate((y_COST, y_HAART))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAUpm05ANOxt","colab_type":"text"},"source":["##1.5. Output"]},{"cell_type":"markdown","metadata":{"id":"QdmhNmNpNiiR","colab_type":"text"},"source":["The results of these preprocessing steps will serve as input for the model. For this reason, the files will be exported to the 'input' folder."]},{"cell_type":"code","metadata":{"id":"ZfXOmtG-iQe0","colab_type":"code","colab":{}},"source":["files = [(\"x_HAART\", x_HAART),\n","         (\"y_HAART\", y_HAART),\n","         (\"x_COST\", x_COST),\n","         (\"y_COST\", y_COST),\n","         (\"x_COSTHAART\", x_COSTHAART),\n","         (\"y_COSTHAART\", y_COSTHAART)]\n","\n","for name, array in files: #Loop over the NumPy array files.\n","  filename = 'input/' + name #Create path to which the data will be saved.\n","  np.save(filename, array) #Save them in the ' input' folder."],"execution_count":0,"outputs":[]}]}
